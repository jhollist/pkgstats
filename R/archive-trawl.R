
#' Trawl a local CRAN archive and extract statistics from all packages
#'
#' @param path Path to local CRAN archive
#' @param archive If `TRUE`, extract statistics for all packages in the
#' `/Archive` sub-directory, otherwise only statistics for main `tarballs`
#' directory (that is, current packages only).
#' @param prev_results Result of previous call to this function, if available.
#' Submitting previous results will ensure that only newer packages not present
#' in previous result will be analysed, with new results simply appended to
#' previous results. This parameter can also specify a file to be read with
#' `readRDS()`.
#' @param results_file Can be used to specify the name or full path of a `.Rds`
#' file to which results should be saved once they have been generated. The
#' '.Rds' extension will be automatically appended, and any other extensions
#' will be ignored.
#' @param chunk_size Divide large archive trawl into chunks of this size, and
#' save intermediate results to local files. These intermediate files can be
#' combined to generate a single `prev_results` file, to enable jobs to be
#' stopped and re-started without having to recalculate all results. These files
#' will be named `pkgstats-results-N.Rds`, where "N" incrementally numbers each
#' file.
#' @param num_cores Number of machine cores to use in parallel, defaulting to
#' single-core processing.
#' @param save_full If `TRUE`, full \link{pkgstats} results are saved for each
#' package to files in `results_path`.
#' @param save_ex_calls If `TRUE`, the results of the `external_calls` component
#' are saved for each package to files in `results_path` (only if `save_full =
#' FALSE`).
#' @param results_path Path to save intermediate files generated by the
#' `chunk_size` parameter described above.
#'
#' @note Each analysis in an archive trawl spawns several \emph{unsupervised}
#' processes, preventing the trawl from running in parallel. Accurate results
#' can only be guaranteed by running this function as a single process.
#'
#' @return A `data.frame` object with one row for each package containing
#' summary statistics generated from the \link{pkgstats_summary} function.
#'
#' @family archive
#' @export
#' @examples
#' # Create fake archive directory with single tarball:
#' f <- system.file ("extdata", "pkgstats_9.9.tar.gz", package = "pkgstats")
#' tarball <- basename (f)
#'
#' archive_path <- file.path (tempdir (), "archive")
#' if (!dir.exists (archive_path)) {
#'     dir.create (archive_path)
#' }
#' path <- file.path (archive_path, tarball)
#' file.copy (f, path)
#' tarball_path <- file.path (archive_path, "tarballs")
#' dir.create (tarball_path, recursive = TRUE)
#' file.copy (path, file.path (tarball_path, tarball))
#' \dontrun{
#' out <- pkgstats_from_archive (tarball_path)
#' }
pkgstats_from_archive <- function (path,
                                   archive = TRUE,
                                   prev_results = NULL,
                                   results_file = NULL,
                                   chunk_size = 1000L,
                                   num_cores = 1L,
                                   save_full = FALSE,
                                   save_ex_calls = FALSE,
                                   results_path = tempdir ()) {

    requireNamespace ("hms")
    requireNamespace ("parallel")

    res <- NULL
    out <- prev_results

    flist <- list_archive_files (path, archive)
    flist <- rm_prev_files (flist, prev_results)
    nfiles <- length (flist)

    if (nfiles > 0) {

        n <- ceiling (nfiles / chunk_size)
        n <- factor (rep (seq (n), each = chunk_size)) [seq (nfiles)]
        flist <- split (flist, f = n)

        message (
            "Starting trawl of ", nfiles,
            " files in ", length (flist), " chunks"
        )

        results_path <- normalizePath (results_path, mustWork = FALSE)
        if (!dir.exists (results_path)) {
            dir.create (results_path)
        }
        results_files <- NULL

        index <- 1 # name of temporary files
        pt0 <- proc.time ()

        for (f in flist) {

            res <- parallel::mclapply (f, function (i) {

                s <- tryCatch (pkgstats::pkgstats (i),
                    error = function (e) NULL
                )

                if (save_full | save_ex_calls) {
                    pkg <- utils::tail (decompose_path (i) [[1]], 1L)
                    pkg <- gsub ("\\.tar\\.gz$", "", pkg)
                    if (save_full) {
                        saveRDS (s, file.path (results_path, pkg))
                    } else if (save_ex_calls) {
                        saveRDS (
                            s$external_calls,
                            file.path (results_path, pkg)
                        )
                    }
                }

                summ <- tryCatch (pkgstats::pkgstats_summary (s),
                    error = function (e) NULL
                )
                if (is.null (summ)) { # pkgstats failed
                    summ <- pkgstats_summary () # null summary
                    p <- strsplit (i, .Platform$file.sep) [[1]]
                    p <- strsplit (utils::tail (p, 1), "\\_") [[1]]
                    summ ["package"] <- p [1]
                    summ ["version"] <-
                        gsub ("\\.tar\\.gz$", "", p [2])
                }
                return (summ)
            }, mc.cores = num_cores)

            fname <- file.path (
                results_path,
                paste0 ("pkgstats-results-", index, ".Rds")
            )
            saveRDS (do.call (rbind, res), fname)
            results_files <- c (results_files, fname)

            prog <- index * chunk_size / nfiles
            prog_fmt <- format (100 * prog, digits = 2)
            pt1 <- as.integer ((proc.time () - pt0) [3])
            t_per_file <- pt1 / (index * chunk_size)
            t_total <- t_per_file * nfiles
            t_rem <- hms::hms (t_total - pt1)

            ndone <- min (c (nfiles, index * chunk_size))

            message (
                "[", ndone, " / ", nfiles,
                "]  = ", prog_fmt, "%; (elapsed, remaining) = (",
                pt1, ", ", t_rem, ")"
            )

            index <- index + 1
        }

        res <- do.call (rbind, lapply (results_files, readRDS))
    }

    out <- rbind (out, res)
    rownames (out) <- NULL

    chk <- file.remove (results_files) # nolint

    if (!is.null (res) & !is.null (results_file)) {

        if (!grepl (.Platform$file.sep, results_file)) {
            results_file <- file.path (".", results_file)
        }
        results_file <- normalizePath (results_file, mustWork = FALSE)

        results_path <- gsub (
            basename (results_file), "",
            results_file
        )
        results_path <- normalizePath (results_path)
        if (!dir.exists (results_path)) {
            stop ("Directory [", results_path, "] does not exist")
        }

        results_file <- basename (results_file)
        results_file <- tools::file_path_sans_ext (results_file)
        results_file <- file.path (
            results_path,
            paste0 (results_file, ".Rds")
        )

        saveRDS (out, results_file)
    }

    invisible (out)
}

list_archive_files <- function (path, recursive = FALSE) {

    if (!grepl ("tarball", path)) {
        if (!dir.exists (file.path (path, "tarballs"))) {
            stop ("path must contain a 'tarballs' directory")
        }
        path <- file.path (path, "tarballs")
    }

    if (basename (path) != "tarballs") {
        stop ("path must be a directory named 'tarballs'")
    }

    if (!dir.exists (path)) {
        stop ("[", path, "] directory does not exist")
    }

    flist <- list.files (
        path,
        recursive = recursive,
        full.names = TRUE,
        pattern = "\\.tar\\.gz$"
    )

    return (normalizePath (flist))
}

#' Remove files for which results have already been generated
#' @param flist Full paths to all tarball files to be analysed
#' @param prev_results `data.frame` of previous results
#' @return Modified version of `flist`, after removing any entires present in
#' `prev_results`.
#' @noRd
rm_prev_files <- function (flist, prev_results) {

    if (!is.null (prev_results)) {

        if (is.character (prev_results)) {
            if (length (prev_results) > 1) {
                stop ("prev_results must be a single-length character")
            }
            if (!file.exists (prev_results)) {
                stop ("file [", prev_results, "] does not exist")
            }
            prev_results <- tryCatch (readRDS (prev_results),
                error = function (e) e
            )
            if (methods::is (prev_results, "error")) {
                stop ("Unable to read prev_results: ", prev_results$message)
            }
        }

        tars <- vapply (
            flist, function (i) {
                utils::tail (strsplit (i, .Platform$file.sep) [[1]], 1)
            },
            character (1)
        )

        prev_tars <- paste0 (
            prev_results$package,
            "_",
            prev_results$version,
            ".tar.gz"
        )

        flist <- flist [which (!tars %in% prev_tars)]
    }

    return (flist)
}

#' Trawl a local CRAN archive to extract function names only from all packages
#'
#' @inheritParams pkgstats_from_archive
#' @return A `data.frame` object with one row for each function in each package
#' and the following columns:
#' \itemize{
#' \item Package name
#' \item Package version
#' \item Function name
#' }
#'
#' @family archive
#' @export
pkgstats_fns_from_archive <- function (path,
                                       archive = FALSE,
                                       prev_results = NULL,
                                       results_file = NULL,
                                       chunk_size = 1000L,
                                       num_cores = 1L,
                                       results_path = tempdir ()) {

    requireNamespace ("hms")
    requireNamespace ("parallel")

    if (!grepl ("tarball", path)) {
        if (!dir.exists (file.path (path, "tarballs"))) {
            stop ("path must contain a 'tarballs' directory")
        }
        path <- file.path (path, "tarballs")
    }

    if (basename (path) != "tarballs") {
        stop ("path must be a directory named 'tarballs'")
    }

    if (!dir.exists (path)) {
        stop ("[", path, "] directory does not exist")
    }

    res <- NULL
    out <- prev_results

    flist <- list.files (
        path,
        recursive = archive,
        full.names = TRUE,
        pattern = "\\.tar\\.gz$"
    )
    flist <- normalizePath (flist)
    flist <- rm_prev_files (flist, prev_results)
    nfiles <- length (flist)

    if (nfiles > 0) {

        n <- ceiling (nfiles / chunk_size)
        n <- factor (rep (seq (n), each = chunk_size)) [seq (nfiles)]
        flist <- split (flist, f = n)

        message (
            "Starting trawl of ", nfiles,
            " files in ", length (flist), " chunks"
        )

        results_path <- normalizePath (results_path, mustWork = FALSE)
        if (!dir.exists (results_path)) {
            dir.create (results_path)
        }
        results_files <- NULL

        index <- 1 # name of temporary files
        pt0 <- proc.time ()

        for (f in flist) {

            res <- parallel::mclapply (f, function (i) {

                tryCatch (
                    pkgstats::pkgstats_fn_names (i),
                    error = function (e) NULL
                )

            }, mc.cores = num_cores)

            fname <- file.path (
                results_path,
                paste0 ("pkgstats-fn-names-results-", index, ".Rds")
            )
            saveRDS (do.call (rbind, res), fname)
            results_files <- c (results_files, fname)

            prog <- index * chunk_size / nfiles
            prog_fmt <- format (100 * prog, digits = 2)
            pt1 <- as.integer ((proc.time () - pt0) [3])
            t_per_file <- pt1 / (index * chunk_size)
            t_total <- t_per_file * nfiles
            t_rem <- hms::hms (t_total - pt1)

            ndone <- min (c (nfiles, index * chunk_size))

            message (
                "[", ndone, " / ", nfiles,
                "]  = ", prog_fmt, "%; (elapsed, remaining) = (",
                pt1, ", ", t_rem, ")"
            )

            index <- index + 1
        }

        res <- do.call (rbind, lapply (results_files, readRDS))
    }

    t_total <- hms::hms (as.integer (proc.time () [3] - pt0 [3]))
    message ("\nTotal time = ", t_total)

    out <- rbind (out, res)
    rownames (out) <- NULL

    chk <- file.remove (results_files) # nolint

    if (!is.null (res) & !is.null (results_file)) {

        if (!grepl (.Platform$file.sep, results_file)) {
            results_file <- file.path (".", results_file)
        }
        results_file <- normalizePath (results_file, mustWork = FALSE)

        results_path <- gsub (
            basename (results_file), "",
            results_file
        )
        results_path <- normalizePath (results_path)
        if (!dir.exists (results_path)) {
            stop ("Directory [", results_path, "] does not exist")
        }

        results_file <- basename (results_file)
        results_file <- tools::file_path_sans_ext (results_file)
        results_file <- file.path (
            results_path,
            paste0 (results_file, ".Rds")
        )

        saveRDS (out, results_file)
    }

    invisible (out)
}
